{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning, \n",
    "    message=\"invalid value encountered in divide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosi_path = r'/home/drew/Desktop/Research/MMSA/datasets/CMU-MOSI/Processed/aligned_50.pkl'\n",
    "with open(mosi_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "train, valid, test = data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = r'/media/drew/data1/DeepLearning/MMSA/datasets/CMU-MOSI/Raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_text', 'audio', 'vision', 'id', 'text', 'text_bert', 'annotations', 'classification_labels', 'regression_labels'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03bSnISJMiM$_$11',\n",
       " '03bSnISJMiM$_$10',\n",
       " '03bSnISJMiM$_$13',\n",
       " '03bSnISJMiM$_$12',\n",
       " '03bSnISJMiM$_$1']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/drew/data1/DeepLearning/MMSA/datasets/CMU-MOSI/Raw/03bSnISJMiM/11.mp4',\n",
       " '/media/drew/data1/DeepLearning/MMSA/datasets/CMU-MOSI/Raw/03bSnISJMiM/10.mp4',\n",
       " '/media/drew/data1/DeepLearning/MMSA/datasets/CMU-MOSI/Raw/03bSnISJMiM/13.mp4',\n",
       " '/media/drew/data1/DeepLearning/MMSA/datasets/CMU-MOSI/Raw/03bSnISJMiM/12.mp4',\n",
       " '/media/drew/data1/DeepLearning/MMSA/datasets/CMU-MOSI/Raw/03bSnISJMiM/1.mp4']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_path(data_root, id_list):\n",
    "    return [join(data_root, *(id + '.mp4').split('$_$')) for id in id_list]\n",
    "data_path_list = get_data_path(data_root, train['id'])\n",
    "data_path_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来处理单个视频文件\n",
    "def process_video(file_path):\n",
    "    # 初始化一个列表来保存RGB帧数据\n",
    "    rgb_frames = []\n",
    "    \n",
    "    # 使用OpenCV打开视频文件\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # 如果没有帧了，跳出循环\n",
    "        \n",
    "        # 转换颜色空间从BGR到RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_frames.append(frame_rgb)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(rgb_frames)\n",
    "\n",
    "# 对数据路径列表使用并行处理\n",
    "def parallel_process_videos(data_path_list):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # 使用map函数并行处理所有视频文件\n",
    "        results = executor.map(process_video, data_path_list)\n",
    "    \n",
    "    # 将结果整合并返回\n",
    "    return list(results)\n",
    "\n",
    "video_frame = parallel_process_videos(data_path_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 360, 640, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frame[3].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
